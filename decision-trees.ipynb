{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom collections import Counter\n\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier as SkDecisionTree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier  # pip install xgboost if needed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:24:49.928462Z","iopub.execute_input":"2025-12-09T15:24:49.928771Z","iopub.status.idle":"2025-12-09T15:24:49.934295Z","shell.execute_reply.started":"2025-12-09T15:24:49.928750Z","shell.execute_reply":"2025-12-09T15:24:49.933234Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Load dataset\ndata = load_breast_cancer()\nX = data.data      # features\ny = data.target    # labels (0/1)\n\n# Train / Test split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(X_train.shape, X_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:24:49.935957Z","iopub.execute_input":"2025-12-09T15:24:49.936586Z","iopub.status.idle":"2025-12-09T15:24:49.968539Z","shell.execute_reply.started":"2025-12-09T15:24:49.936554Z","shell.execute_reply":"2025-12-09T15:24:49.967279Z"}},"outputs":[{"name":"stdout","text":"(455, 30) (114, 30)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def entropy(y):\n    \"\"\"Compute entropy of label array y.\"\"\"\n    counts = np.bincount(y)\n    probs = counts[counts > 0] / len(y)\n    return -np.sum(probs * np.log2(probs))\n\n\ndef gini(y):\n    \"\"\"Compute gini impurity of label array y.\"\"\"\n    counts = np.bincount(y)\n    probs = counts[counts > 0] / len(y)\n    return 1.0 - np.sum(probs**2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:24:49.969545Z","iopub.execute_input":"2025-12-09T15:24:49.969808Z","iopub.status.idle":"2025-12-09T15:24:49.977635Z","shell.execute_reply.started":"2025-12-09T15:24:49.969788Z","shell.execute_reply":"2025-12-09T15:24:49.976555Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def best_split(X, y, criterion=\"entropy\"):\n    \"\"\"\n    Find best feature index and threshold to split on.\n    Returns: (best_feature, best_threshold, best_impurity_gain)\n    \"\"\"\n    n_samples, n_features = X.shape\n    if n_samples <= 1:\n        return None, None, 0\n\n    if criterion == \"entropy\":\n        impurity_func = entropy\n    else:\n        impurity_func = gini\n\n    parent_impurity = impurity_func(y)\n    best_gain = 0.0\n    best_feature = None\n    best_threshold = None\n\n    for feature_idx in range(n_features):\n        # Consider unique sorted values of this feature as candidate thresholds\n        values = X[:, feature_idx]\n        thresholds = np.unique(values)\n\n        for t in thresholds:\n            left_mask = values <= t\n            right_mask = ~left_mask\n\n            if left_mask.sum() == 0 or right_mask.sum() == 0:\n                continue  # invalid split\n\n            y_left, y_right = y[left_mask], y[right_mask]\n\n            n_left, n_right = len(y_left), len(y_right)\n            n_total = n_left + n_right\n\n            impurity_left = impurity_func(y_left)\n            impurity_right = impurity_func(y_right)\n\n            child_impurity = (n_left / n_total) * impurity_left + (n_right / n_total) * impurity_right\n            gain = parent_impurity - child_impurity\n\n            if gain > best_gain:\n                best_gain = gain\n                best_feature = feature_idx\n                best_threshold = t\n\n    return best_feature, best_threshold, best_gain\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:24:49.979362Z","iopub.execute_input":"2025-12-09T15:24:49.979756Z","iopub.status.idle":"2025-12-09T15:24:49.995578Z","shell.execute_reply.started":"2025-12-09T15:24:49.979735Z","shell.execute_reply":"2025-12-09T15:24:49.994604Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class TreeNode:\n    def __init__(self, *, feature=None, threshold=None, left=None, right=None, value=None):\n        self.feature = feature        # index of feature to split on\n        self.threshold = threshold    # threshold value\n        self.left = left              # left child (TreeNode)\n        self.right = right            # right child (TreeNode)\n        self.value = value            # class label if leaf\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:24:49.996859Z","iopub.execute_input":"2025-12-09T15:24:49.997140Z","iopub.status.idle":"2025-12-09T15:24:50.018909Z","shell.execute_reply.started":"2025-12-09T15:24:49.997113Z","shell.execute_reply":"2025-12-09T15:24:50.017856Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class MyDecisionTreeClassifier:\n    def __init__(self, criterion=\"entropy\", max_depth=None, min_samples_split=2):\n        assert criterion in (\"entropy\", \"gini\")\n        self.criterion = criterion\n        self.max_depth = max_depth\n        self.min_samples_split = min_samples_split\n        self.root = None\n\n    def fit(self, X, y):\n        self.n_classes_ = len(np.unique(y))\n        self.root = self._build_tree(X, y, depth=0)\n\n    def _build_tree(self, X, y, depth):\n        num_samples, num_features = X.shape\n        num_labels = len(np.unique(y))\n\n        # Stopping conditions\n        if (self.max_depth is not None and depth >= self.max_depth) or \\\n           num_labels == 1 or \\\n           num_samples < self.min_samples_split:\n            leaf_value = self._most_common_label(y)\n            return TreeNode(value=leaf_value)\n\n        feature, threshold, gain = best_split(X, y, criterion=self.criterion)\n\n        if feature is None or gain == 0:\n            # No useful split\n            leaf_value = self._most_common_label(y)\n            return TreeNode(value=leaf_value)\n\n        # Split dataset\n        left_mask = X[:, feature] <= threshold\n        right_mask = ~left_mask\n\n        left = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n        right = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n\n        return TreeNode(feature=feature, threshold=threshold, left=left, right=right)\n\n    def _most_common_label(self, y):\n        counter = Counter(y)\n        return counter.most_common(1)[0][0]\n\n    def _predict_single(self, x, node):\n        if node.value is not None:\n            return node.value\n\n        if x[node.feature] <= node.threshold:\n            return self._predict_single(x, node.left)\n        else:\n            return self._predict_single(x, node.right)\n\n    def predict(self, X):\n        return np.array([self._predict_single(x, self.root) for x in X])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:24:50.019908Z","iopub.execute_input":"2025-12-09T15:24:50.020146Z","iopub.status.idle":"2025-12-09T15:24:50.037351Z","shell.execute_reply.started":"2025-12-09T15:24:50.020127Z","shell.execute_reply":"2025-12-09T15:24:50.036510Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Custom Decision Tree using Entropy\nmy_dt_entropy = MyDecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\nmy_dt_entropy.fit(X_train, y_train)\ny_pred_my_entropy = my_dt_entropy.predict(X_test)\n\n# Custom Decision Tree using Gini\nmy_dt_gini = MyDecisionTreeClassifier(criterion=\"gini\", max_depth=5)\nmy_dt_gini.fit(X_train, y_train)\ny_pred_my_gini = my_dt_gini.predict(X_test)\n\n# Sklearn Decision Tree\nsk_dt = SkDecisionTree(criterion=\"entropy\", max_depth=5, random_state=42)\nsk_dt.fit(X_train, y_train)\ny_pred_sk = sk_dt.predict(X_test)\n\nprint(\"Accuracy (My DT - Entropy):\", accuracy_score(y_test, y_pred_my_entropy))\nprint(\"Accuracy (My DT - Gini):   \", accuracy_score(y_test, y_pred_my_gini))\nprint(\"Accuracy (Sklearn DT):     \", accuracy_score(y_test, y_pred_sk))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:24:50.038240Z","iopub.execute_input":"2025-12-09T15:24:50.038564Z","iopub.status.idle":"2025-12-09T15:24:54.086420Z","shell.execute_reply.started":"2025-12-09T15:24:50.038536Z","shell.execute_reply":"2025-12-09T15:24:54.085375Z"}},"outputs":[{"name":"stdout","text":"Accuracy (My DT - Entropy): 0.9385964912280702\nAccuracy (My DT - Gini):    0.9298245614035088\nAccuracy (Sklearn DT):      0.9298245614035088\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Random Forest\nrf = RandomForestClassifier(\n    n_estimators=100,\n    max_depth=5,\n    random_state=42\n)\nrf.fit(X_train, y_train)\ny_pred_rf_train = rf.predict(X_train)\ny_pred_rf_test = rf.predict(X_test)\n\n# XGBoost\nxgb = XGBClassifier(\n    n_estimators=200,\n    max_depth=4,\n    learning_rate=0.05,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    eval_metric=\"logloss\",\n    random_state=42\n)\nxgb.fit(X_train, y_train)\ny_pred_xgb_train = xgb.predict(X_train)\ny_pred_xgb_test = xgb.predict(X_test)\n\nprint(\"\\n=== Model Accuracies ===\")\nprint(\"My DT (Entropy) - Train:\", accuracy_score(y_train, my_dt_entropy.predict(X_train)))\nprint(\"My DT (Entropy) - Test :\", accuracy_score(y_test,  y_pred_my_entropy))\n\nprint(\"Sklearn DT      - Train:\", accuracy_score(y_train, sk_dt.predict(X_train)))\nprint(\"Sklearn DT      - Test :\", accuracy_score(y_test,  y_pred_sk))\n\nprint(\"Random Forest   - Train:\", accuracy_score(y_train, y_pred_rf_train))\nprint(\"Random Forest   - Test :\", accuracy_score(y_test,  y_pred_rf_test))\n\nprint(\"XGBoost         - Train:\", accuracy_score(y_train, y_pred_xgb_train))\nprint(\"XGBoost         - Test :\", accuracy_score(y_test,  y_pred_xgb_test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:24:54.088449Z","iopub.execute_input":"2025-12-09T15:24:54.088733Z","iopub.status.idle":"2025-12-09T15:24:54.528816Z","shell.execute_reply.started":"2025-12-09T15:24:54.088707Z","shell.execute_reply":"2025-12-09T15:24:54.528094Z"}},"outputs":[{"name":"stdout","text":"\n=== Model Accuracies ===\nMy DT (Entropy) - Train: 0.9912087912087912\nMy DT (Entropy) - Test : 0.9385964912280702\nSklearn DT      - Train: 0.9912087912087912\nSklearn DT      - Test : 0.9298245614035088\nRandom Forest   - Train: 0.9934065934065934\nRandom Forest   - Test : 0.956140350877193\nXGBoost         - Train: 1.0\nXGBoost         - Test : 0.956140350877193\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Random Forest\nrf = RandomForestClassifier(\n    n_estimators=100,\n    max_depth=5,\n    random_state=42\n)\nrf.fit(X_train, y_train)\ny_pred_rf_train = rf.predict(X_train)\ny_pred_rf_test = rf.predict(X_test)\n\n# XGBoost\nxgb = XGBClassifier(\n    n_estimators=200,\n    max_depth=4,\n    learning_rate=0.05,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    eval_metric=\"logloss\",\n    random_state=42\n)\nxgb.fit(X_train, y_train)\ny_pred_xgb_train = xgb.predict(X_train)\ny_pred_xgb_test = xgb.predict(X_test)\n\nprint(\"\\n=== Model Accuracies ===\")\nprint(\"My DT (Entropy) - Train:\", accuracy_score(y_train, my_dt_entropy.predict(X_train)))\nprint(\"My DT (Entropy) - Test :\", accuracy_score(y_test,  y_pred_my_entropy))\n\nprint(\"Sklearn DT      - Train:\", accuracy_score(y_train, sk_dt.predict(X_train)))\nprint(\"Sklearn DT      - Test :\", accuracy_score(y_test,  y_pred_sk))\n\nprint(\"Random Forest   - Train:\", accuracy_score(y_train, y_pred_rf_train))\nprint(\"Random Forest   - Test :\", accuracy_score(y_test,  y_pred_rf_test))\n\nprint(\"XGBoost         - Train:\", accuracy_score(y_train, y_pred_xgb_train))\nprint(\"XGBoost         - Test :\", accuracy_score(y_test,  y_pred_xgb_test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:24:54.529622Z","iopub.execute_input":"2025-12-09T15:24:54.529879Z","iopub.status.idle":"2025-12-09T15:24:54.960694Z","shell.execute_reply.started":"2025-12-09T15:24:54.529859Z","shell.execute_reply":"2025-12-09T15:24:54.959988Z"}},"outputs":[{"name":"stdout","text":"\n=== Model Accuracies ===\nMy DT (Entropy) - Train: 0.9912087912087912\nMy DT (Entropy) - Test : 0.9385964912280702\nSklearn DT      - Train: 0.9912087912087912\nSklearn DT      - Test : 0.9298245614035088\nRandom Forest   - Train: 0.9934065934065934\nRandom Forest   - Test : 0.956140350877193\nXGBoost         - Train: 1.0\nXGBoost         - Test : 0.956140350877193\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"print(\"\\nTop 5 Feature Importances (Random Forest):\")\nrf_importances = rf.feature_importances_\nfor idx in np.argsort(rf_importances)[::-1][:5]:\n    print(f\"{data.feature_names[idx]}: {rf_importances[idx]:.4f}\")\n\nprint(\"\\nTop 5 Feature Importances (XGBoost):\")\nxgb_importances = xgb.feature_importances_\nfor idx in np.argsort(xgb_importances)[::-1][:5]:\n    print(f\"{data.feature_names[idx]}: {xgb_importances[idx]:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T15:24:54.961483Z","iopub.execute_input":"2025-12-09T15:24:54.961741Z","iopub.status.idle":"2025-12-09T15:24:54.976619Z","shell.execute_reply.started":"2025-12-09T15:24:54.961721Z","shell.execute_reply":"2025-12-09T15:24:54.975804Z"}},"outputs":[{"name":"stdout","text":"\nTop 5 Feature Importances (Random Forest):\nworst area: 0.1383\nworst concave points: 0.1330\nworst radius: 0.1008\nmean concave points: 0.0985\nworst perimeter: 0.0722\n\nTop 5 Feature Importances (XGBoost):\nworst perimeter: 0.2547\nworst radius: 0.1225\nmean concave points: 0.1222\nworst area: 0.0915\nworst concave points: 0.0645\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}